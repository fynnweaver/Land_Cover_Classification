{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89617dd-ba71-4286-8c48-c518f371936f",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ff439-4f50-441e-8dfe-7fef9a953a0b",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668e86a5-9f7f-4e8a-b842-f9662ae3c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#system packages\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#spatial packages\n",
    "from rastertodataframe import raster_to_dataframe\n",
    "from osgeo.gdalconst import *\n",
    "from osgeo import gdal\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "#processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#modeling\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "\n",
    "#misc\n",
    "from math import floor\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bfd9a1-6dcd-4fab-8bb9-24af7e85e422",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1647aa-5ff2-4eb2-9f9a-c0c8455c4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom functions\n",
    "\n",
    "#function to create histogram of scenes class frequency\n",
    "def nrcan_hist(img):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from collections import Counter\n",
    "\n",
    "    im_array = np.array(img)\n",
    "\n",
    "    #last line is bad values \n",
    "    im_array = im_array[:-1]\n",
    "\n",
    "    #value count\n",
    "    freq = Counter(im_array.flatten())\n",
    "\n",
    "    plt.bar(freq.keys(), freq.values())\n",
    "    plt.xlim([-1, 20])\n",
    "    \n",
    "#function to turn tiff to df\n",
    "def tiff_to_df_colab(path):\n",
    "\n",
    "    #Create folder path and list variables\n",
    "    folder_path = path\n",
    "    file_list = glob.glob(folder_path + \"/*.tiff\")\n",
    "\n",
    "    #initiate empty dataframe\n",
    "    main_dataframe = pd.DataFrame()\n",
    "\n",
    "    for i in file_list:\n",
    "        data = raster_to_dataframe(i)\n",
    "  \n",
    "        #extract name of band from file path\n",
    "        band_info = str(i).split('/')[-1]\n",
    "        band_name = band_info[-14:-11]\n",
    "        #rename with band name\n",
    "        data = data.rename(columns = {'Band_1': band_name})\n",
    "        #merge into main dataframe\n",
    "        main_dataframe = pd.concat([main_dataframe, data], axis = 1)\n",
    "\n",
    "    return main_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8892c2d2-cc8e-4526-b328-80e0db87d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B09</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>B8A</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.2729</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.2777</td>\n",
       "      <td>0.3842</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>0.2757</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.3886</td>\n",
       "      <td>0.3842</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1104</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.3128</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>0.3254</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.3376</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B01     B02     B03     B04     B05     B06     B07     B08     B09  \\\n",
       "0  0.0934  0.1228  0.1588  0.2052  0.2344  0.2549  0.2729  0.2928  0.2947   \n",
       "1  0.0890  0.1163  0.1507  0.1944  0.2210  0.2390  0.2560  0.2761  0.2777   \n",
       "2  0.0893  0.1157  0.1511  0.1944  0.2199  0.2363  0.2552  0.2752  0.2764   \n",
       "3  0.1104  0.1609  0.1919  0.2144  0.2526  0.2926  0.3128  0.3342  0.3254   \n",
       "4  0.0723  0.0913  0.1220  0.1250  0.1730  0.2769  0.3134  0.3368  0.3366   \n",
       "\n",
       "      B11     B12     B8A   y  \n",
       "0  0.3868  0.3853  0.2917  15  \n",
       "1  0.3842  0.3827  0.2757  15  \n",
       "2  0.3886  0.3842  0.2765  15  \n",
       "3  0.3672  0.3320  0.3325  15  \n",
       "4  0.3020  0.2353  0.3376  15  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in raw bands\n",
    "tor_raws = tiff_to_df_colab('../data_tests/scene_5/raws')\n",
    "sim_raws = tiff_to_df_colab('../data_tests/simcoe_york/raws')\n",
    "lab_raws = tiff_to_df_colab('../data_tests/labrador/raws')\n",
    "james_raws = tiff_to_df_colab('../data_tests/james_bay/raws')\n",
    "\n",
    "#load nrcan data\n",
    "sim_nrcan = raster_to_dataframe('../data_tests/simcoe_york/Simcoe_York_2019.tif')\n",
    "lab_nrcan = raster_to_dataframe('../data_tests/labrador/NRCAN_transformed.tif')\n",
    "james_nrcan = raster_to_dataframe('../data_tests/james_bay/James_Bay_Med.tif')\n",
    "tor_nrcan = raster_to_dataframe('../data_tests/scene_5/NRCAN_transformed.tif')\n",
    "\n",
    "#add label column\n",
    "#sask_raws['y'] = sask_labels\n",
    "tor_raws['y'] = tor_nrcan\n",
    "sim_raws['y'] = sim_nrcan\n",
    "lab_raws['y'] = lab_nrcan\n",
    "james_raws['y'] = james_nrcan\n",
    "\n",
    "tor_raws.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae278e8-f102-404b-946b-9f52fbc76797",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca56c1a3-ce56-4a62-a09c-b1191b04d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom functions\n",
    "def clean_raws(dataframe):\n",
    "    clean_all = pd.DataFrame()\n",
    "\n",
    "    #for each category\n",
    "    for category in dataframe.y.unique():\n",
    "        #initialize new dataframe using first band of current category\n",
    "        clean_df = dataframe.loc[dataframe['y'] == category]['B01']\n",
    "\n",
    "        #get quartile range\n",
    "        Q1 = clean_df.quantile(0.25)\n",
    "        Q3 = clean_df.quantile(0.75)\n",
    "        outlier = Q3 * 2\n",
    "        #delete values not within\n",
    "        clean_df = clean_df[clean_df < outlier].reset_index()\n",
    "    \n",
    "        #for every subsequent band do the same thing and merge\n",
    "        for band in dataframe.columns[1:-1]:\n",
    "            temp_df = dataframe.loc[dataframe['y'] == category][band]\n",
    "            \n",
    "            Q1 = temp_df.quantile(0.25)\n",
    "            Q3 = temp_df.quantile(0.75)\n",
    "            outlier = Q3 * 2\n",
    "\n",
    "            temp_df = temp_df[temp_df < outlier].reset_index()\n",
    "            clean_df = clean_df.merge(temp_df, how= 'inner', on = 'index')\n",
    "        \n",
    "        clean_df['y'] = category    \n",
    "        #append each cleaned category dataframe to dict\n",
    "        clean_all = pd.concat([clean_all, clean_df])\n",
    "    \n",
    "    return clean_all.drop('index', axis = 1)\n",
    "\n",
    "def gaussian_raws(path_to_dir,  sigma = 1, nrcan_name = 'NRCAN_transformed.tif', index = [-14, -11]):\n",
    "    raw_files = list(os.listdir(path_to_dir))\n",
    "    \n",
    "    band_1 = gdal.Open(os.path.join(path_to_dir, raw_files[0]))\n",
    "\n",
    "    gauss_df = pd.DataFrame(np.array(band_1.ReadAsArray()).flatten(), columns = ['B01'])\n",
    "    for i in raw_files[1:]:\n",
    "        raw_img = gdal.Open(os.path.join(path_to_dir, i))\n",
    "        rows = raw_img.RasterYSize\n",
    "        cols = raw_img.RasterXSize\n",
    "        \n",
    "        raw_array = np.array(raw_img.ReadAsArray())\n",
    "        \n",
    "        raw_gauss = gaussian_filter(raw_array, sigma = sigma)\n",
    "        \n",
    "        raw_gauss = raw_gauss.flatten()\n",
    "        gauss_df[i[index[0]:index[1]]] = raw_gauss\n",
    "    \n",
    "    nrcan = gdal.Open(os.path.join(path_to_dir, '..', nrcan_name))\n",
    "    nrcan_array = np.array(nrcan.ReadAsArray())\n",
    "    \n",
    "    gauss_df['y'] = nrcan_array.flatten()\n",
    "    return gauss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49ca9769-4b46-4119-9bfb-b5f8ae83ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ec1719d9a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#comparing example band distribution within each class across two extents\n",
    "plt.scatter(lab_raws['B01'], lab_raws.y)\n",
    "plt.scatter(sim_raws['B01'], sim_raws.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56698ee3-d523-458a-8740-0e9ae2a6929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertical concat\n",
    "main_dataframe = pd.concat([tor_raws, sim_raws, lab_raws, james_raws])\n",
    "main_dataframe = main_dataframe.reset_index().drop('index', axis = 1)\n",
    "#main_dataframe = lab_raws\n",
    "#main_dataframe = clean_raws(main_dataframe)\n",
    "                \n",
    "sim_gauss = gaussian_raws('../data_tests/simcoe_york/raws', nrcan_name = 'Simcoe_York_2019.tif')\n",
    "lab_gauss = gaussian_raws('../data_tests/labrador/raws')\n",
    "james_gauss = gaussian_raws('../data_tests/james_bay/raws', nrcan_name = 'James_Bay_Med.tif')\n",
    "tor_gauss = gaussian_raws('../data_tests/scene_5/raws')\n",
    "main_dataframe = pd.concat([tor_gauss, james_gauss, sim_gauss, lab_gauss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063de649-ea71-4253-8765-12f74b9f2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669c626-4874-4b42-9be6-bac28163c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulization of band distribution for each class in the main dataframe\n",
    "\n",
    "#number of axes = number of possible combos\n",
    "fig, axes = plt.subplots(4, 3, figsize = (15, 40))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    \n",
    "    #index of columns\n",
    "    X_scatter = main_dataframe[main_dataframe.columns[:-1][i]]\n",
    "    Y_scatter = main_dataframe['y']\n",
    "    \n",
    "    # scatter current combination\n",
    "    ax.scatter(X_scatter, Y_scatter)\n",
    "    ax.set_title(main_dataframe.columns[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc121e1-30ac-4af1-bced-0c5ad4747023",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d352d-c442-476d-9ab9-54fd8d2133fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting an equal sample from each image for each class -- UNDER CONSTRUCTION--\n",
    "\n",
    "#create list of input images\n",
    "train_images = [tor_gauss, james_gauss, sim_gauss, lab_gauss]\n",
    "\n",
    "#empty subset frame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "#for each image in input images\n",
    "for image in train_images:\n",
    "    \n",
    "    #drop 0\n",
    "    image = image.loc[image.y != 0]\n",
    "    \n",
    "    #get class totals\n",
    "    image_classes = image.value_counts('y').sort_index() \n",
    "    \n",
    "    #define class threshold and threshold for class in each image\n",
    "    class_threshold = 20000\n",
    "    image_threshold = int(class_threshold / (len(train_images)))\n",
    "    \n",
    "    #init empty frame to store data for each image\n",
    "    subset = pd.DataFrame()\n",
    "    \n",
    "    #for each class\n",
    "    for label in image_classes.index:\n",
    "        #try to sample the image class threshold\n",
    "        try:\n",
    "            label_subset = image.loc[image.y == label[0]].sample(n= image_threshold, random_state=24)\n",
    "        #if not possible (threshold > existing class count) then sample class count\n",
    "        except:\n",
    "            label_subset = image.loc[image.y == label[0]].sample(n = (image_threshold - 5000), random_state=24)\n",
    "        \n",
    "        #concat class subset into data \n",
    "        subset = pd.concat([subset, label_subset])\n",
    "        \n",
    "    #concat data into subset frame\n",
    "    data = pd.concat([data, subset])\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7813d4-fcfb-463b-a55d-e382caeda1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts('y').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea4775-7b72-4b20-9f0e-45d02956576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9812500, 13)\n",
      "y \n",
      "0      181478\n",
      "1      701398\n",
      "2      155025\n",
      "5      721844\n",
      "6      399027\n",
      "8      582855\n",
      "10      93912\n",
      "11     165666\n",
      "12     639747\n",
      "13     631736\n",
      "14      99622\n",
      "15    3010586\n",
      "16     495329\n",
      "17     661781\n",
      "18    1225374\n",
      "19      47120\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check dataframe shape and print class value counts\n",
    "print(main_dataframe.shape)\n",
    "main_classes = main_dataframe.value_counts('y').sort_index() \n",
    "print(main_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eec0a11-1bfd-4485-84f4-f06ca88773d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450000, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y \n",
       "1     30000\n",
       "2     30000\n",
       "5     30000\n",
       "6     30000\n",
       "8     30000\n",
       "10    30000\n",
       "11    30000\n",
       "12    30000\n",
       "13    30000\n",
       "14    30000\n",
       "15    30000\n",
       "16    30000\n",
       "17    30000\n",
       "18    30000\n",
       "19    30000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final clean\n",
    "#drop 0\n",
    "main_dataframe = main_dataframe.loc[main_dataframe.y != 0]\n",
    "\n",
    "#select classes above threshold\n",
    "threshold = 30000\n",
    "top_classes = main_classes[main_classes > threshold].reset_index().y\n",
    "\n",
    "#save dataframe subset of those classes\n",
    "main_subset = main_dataframe.loc[main_dataframe['y'].isin(top_classes.values)]\n",
    "\n",
    "#take smallest value rounded down to nearest 1000\n",
    "smallest_class = int(floor(min(main_subset.value_counts('y').sort_index().values)/ 1000)) * 1000\n",
    "#subsampling - comment out for full set\n",
    "smallest_class = threshold\n",
    "\n",
    "#take subset of each class equal to smallest class value\n",
    "data = main_subset.groupby(\"y\").sample(n=smallest_class, random_state=24)\n",
    "data.to_csv('data/testtrain.csv', index = False)\n",
    "\n",
    "print(data.shape)\n",
    "data.value_counts('y').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "489e0347-82a4-4aec-b26f-78330cd2b628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2798958, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataframe = clean_raws(data)\n",
    "main_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7cd9bd5-9afe-41ee-8ffa-6d7c5d56ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y \n",
       "1     256443\n",
       "2     424688\n",
       "5     230842\n",
       "6     115226\n",
       "8     209565\n",
       "10     98048\n",
       "11     39655\n",
       "12    442816\n",
       "13     65620\n",
       "14     86285\n",
       "15    105666\n",
       "16    275940\n",
       "17    170151\n",
       "18    238088\n",
       "19     39925\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataframe.value_counts('y').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb18a4-a6f3-4ae2-b809-86417798e1ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbabd976-3c7d-4d36-ae42-96e1be7cb85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75286158 0.14284694 0.04513111 0.01297499 0.01261466 0.01230551]\n"
     ]
    }
   ],
   "source": [
    "y = data.y\n",
    "X = data.drop('y', axis = 1)\n",
    "\n",
    "#Dimensionality reduction - replace X with X_pca and run to try\n",
    "pca = PCA(n_components = 6)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, train_size=0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253a73a-ed05-4e4b-af81-313e18c5343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#scaler = StandardScaler()\n",
    "#X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a14d5-c442-4893-a070-344ac5c38d4c",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608da02-1033-4dbb-a65c-9f9322cc3faf",
   "metadata": {},
   "source": [
    "Random Forest, SVC, XGBoost [stretch] CNN\n",
    "\n",
    "Iteration details:\n",
    "- toronto, simcoe, sask, labrador = standard bands, no parameters, 5K each value, no scaling, in turn toronto, simcoe, sask, labrador extents only\n",
    "- Base run = standard bands, no parameters, 5K each value, no scaling, sim and lab\n",
    "- scaled = standard bands, no params, 5K each value, StandardScaler() -> improved SVC, sask and tor\n",
    "- large set = standard bands, no parameters, 18K each value, no scaling, sim and lab\n",
    "- gaussian = standard bands transformed via gaussian filter, 18K each value, no scaling, sim and lab\n",
    "- demo = random forest applied to demo data\n",
    "    - version_1 = 31.41% trained on sim & lab 18K each\n",
    "    - version_2 =  31.55% trained on gaussian (sigma 5) sim & lab, 18K each\n",
    "    - version_3 = 33.22% trained on gaussian (sigma 1) sim & lab, 18K each\n",
    "    - version_4 = 37.49% trained on gaussian (sigma 1) sim, lab, tor and james, 40K each random\n",
    "    - version_5 = 34.21% trained on sim, lab, tor, james all bands, 40K each random\n",
    "    - version_6 = [] trained on gaussian (sigma 1) sim, lab, tor and james, outliers (Q3 * 2) removed, 30K each \n",
    "\n",
    "Parameterization note: so far best results for RFC come from default with n_estimators = 300 with accuracy around 58.74 for source extent tests -> drops to 30 for demo test\n",
    "\n",
    "To do:\n",
    "- ensure all raws are aligned to a common 60 m res grid (downsampling all but b1 and b9)\n",
    "- scaling sim & lab for svc -> if goes well svc parametrization\n",
    "- basic NN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98ce992f-2d99-4011-85d5-d64722d3823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up save path for images\n",
    "confusion_path = 'confusion_matrices/'\n",
    "group_folder = 'base_run/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efde8bc-5370-4b59-abd2-efee5facc6fb",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f95f0-f1d3-4182-97c6-7f9a5abf53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state = 0,  n_estimators = 300, max_depth = 25, max_features = 2).fit(X_train, y_train)\n",
    "\n",
    "#get accuracy\n",
    "forest_pred = forest.predict(X_test)\n",
    "print(accuracy_score(y_test, forest_pred))\n",
    "\n",
    "#plot confusion matrix\n",
    "cm_forest = confusion_matrix(y_test, forest_pred)\n",
    "cm_forest_fig = ConfusionMatrixDisplay(confusion_matrix = cm_forest, display_labels = forest.classes_)\n",
    "cm_forest_fig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354d6a6-2144-4f8e-92b2-e93c14bc96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#band weight\n",
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7d92c-39c8-4b00-b2db-71be988caefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "cm_forest_fig.figure_.savefig(os.path.join(confusion_path, group_folder, 'forest.png'))\n",
    "print(classification_report(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bbc8ee-8e1f-45cf-8f0f-b98bbdb9f7ef",
   "metadata": {},
   "source": [
    "### Toronto extent test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364754ff-feff-4d54-98f3-77797c95cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get gaussian version of toronto\n",
    "gauss_test = gaussian_raws('../data_tests/scene_5/raws')\n",
    "gauss_test.head()\n",
    "\n",
    "gauss_test['y'] = gauss_test['y'].replace({0:18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87d41d-911e-49d6-9269-12740ffe1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y values from gaussian or default raw bands\n",
    "#y_tor = tor_raws.y\n",
    "#X_tor = tor_raws.drop('y', axis = 1)\n",
    "\n",
    "y_tor = gauss_test.y\n",
    "X_tor = gauss_test.drop('y', axis = 1)\n",
    "\n",
    "#optional PCA, to use replace X_tor in predict with X_tor_pca\n",
    "pca = PCA(n_components = 6)\n",
    "X_tor_pca = pca.fit_transform(X_tor)\n",
    "\n",
    "#predict\n",
    "tor_pred = forest.predict(X_tor)\n",
    "print(accuracy_score(y_tor, tor_pred))\n",
    "\n",
    "#display\n",
    "cm_forest = confusion_matrix(y_tor, tor_pred)\n",
    "cm_forest_fig = ConfusionMatrixDisplay(confusion_matrix = cm_forest, display_labels = forest.classes_)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_forest_fig.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc8577-54d4-41fb-a954-d27a0fde14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display prediction map\n",
    "map_pred = np.asarray(tor_pred).reshape(tor_nrcan.height, tor_nrcan.width)\n",
    "cmap = cm.get_cmap('jet', 7)    # 11 discrete colors\n",
    "prediction_map = plt.imshow(map_pred, cmap=cmap)\n",
    "\n",
    "#save\n",
    "#prediction_map.figure.savefig(os.path.join(confusion_path, 'gaussian', 'map_tor.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4973808-9485-4674-8c94-2698e4d51300",
   "metadata": {},
   "source": [
    "### Demo test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83d63e-ed2f-4336-bdbe-3affa716bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import demo test data\n",
    "demo_raw = pd.read_csv('../data_tests/demo_site.csv')\n",
    "demo_raw.land_cover = demo_raw.land_cover.astype('int')\n",
    "demo_raw.head()\n",
    "\n",
    "#test 2 - demo\n",
    "y_demo = demo_raw.land_cover\n",
    "X_demo = demo_raw.drop('land_cover', axis = 1)\n",
    "print(X_demo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c0888-a31d-48b8-98bc-a4a9ce9d2e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into matrices to perform gaussian then convert back into 1d array and append to dataframe\n",
    "X_demo_gauss = pd.DataFrame()\n",
    "for band in X_demo.columns:\n",
    "    band = X_demo.columns[1]\n",
    "    reconstruct = np.asarray(X_demo[band]).reshape(2500, 2100).T\n",
    "    recon_gauss = gaussian_filter(reconstruct, sigma = 1)\n",
    "    X_demo_gauss[band] = recon_gauss.flatten()\n",
    "    \n",
    "#compare demo input and gauss output\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax1 = fig.add_subplot(121)  # left side\n",
    "ax2 = fig.add_subplot(122)  # right side\n",
    "\n",
    "ax1.imshow(reconstruct)\n",
    "ax2.imshow(recon_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813fa36-5513-45db-9770-2e4e36068c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_demo = gaussian_raws('../data_tests/demo/raws', nrcan_name = 'land_cover.tif', index = [0, 3])\n",
    "\n",
    "#select X values from gaussian dataframe\n",
    "X_demo = gauss_demo.drop('y', axis = 1)\n",
    "X_demo.head()\n",
    "\n",
    "#reshape to use y_demo with gaussian X\n",
    "y_demo = y_demo.values.reshape(2500, 2100).T\n",
    "y_demo = y_demo.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bcefe-d3c7-4604-9145-9b358732c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions\n",
    "demo_pred = forest.predict(X_demo)\n",
    "#demo_pred = forest.predict(X_demo_gauss)\n",
    "\n",
    "#accuracy\n",
    "print(accuracy_score(y_demo, demo_pred))\n",
    "\n",
    "#confusion matrix\n",
    "cm_forest = confusion_matrix(y_demo, demo_pred)\n",
    "cm_forest_fig = ConfusionMatrixDisplay(confusion_matrix = cm_forest, display_labels = forest.classes_)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cm_forest_fig.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25a835-ed77-4ef5-9bab-fd507d215c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot demo prediction map\n",
    "map_pred = np.asarray(demo_pred).reshape(2100, 2500)\n",
    "cmap = cm.get_cmap('jet', 7)    # 11 discrete colors\n",
    "prediction_map = plt.imshow(map_pred, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6d984-f4e6-488a-bb8d-c4ff3331ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save confusion matrix\n",
    "cm_forest_fig.figure_.savefig(os.path.join(confusion_path, 'demo', 'version_4.png'))\n",
    "\n",
    "#save prediction map\n",
    "prediction_map.figure.savefig(os.path.join(confusion_path, 'demo', 'map_4.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827392e3-d0b2-4090-a8ad-706b789fdd37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13171bf-e89a-45e2-a959-f97ada3add3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different SVC kernels - sig performed less then 1 percent on subsample so its removed\n",
    "#linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "#rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "#sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f1d3b-4998-4346-b66f-776b1660d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict from X_test\n",
    "#linear_pred = linear.predict(X_test)\n",
    "poly_pred = poly.predict(X_test)\n",
    "#rbf_pred = rbf.predict(X_test)\n",
    "#sig_pred = sig.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8b191-b653-4754-b2c4-b23552ea3eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the accuracy and print it for all 4 kernel functions\n",
    "#accuracy_lin = linear.score(X_test, y_test)\n",
    "accuracy_poly = poly.score(X_test, y_test)\n",
    "#accuracy_rbf = rbf.score(X_test, y_test)\n",
    "#accuracy_sig = sig.score(X_test, y_test)\n",
    "\n",
    "# creating a confusion matrix\n",
    "#cm_lin = confusion_matrix(y_test, linear_pred)\n",
    "cm_poly = confusion_matrix(y_test, poly_pred)\n",
    "#cm_rbf = confusion_matrix(y_test, rbf_pred)\n",
    "#cm_sig = confusion_matrix(y_test, sig_pred)\n",
    "\n",
    "#visual confusion matrix\n",
    "#cm_lin_fig = ConfusionMatrixDisplay(confusion_matrix = cm_lin, display_labels = linear.classes_)\n",
    "cm_poly_fig = ConfusionMatrixDisplay(confusion_matrix = cm_poly, display_labels = poly.classes_)\n",
    "#cm_rbf_fig = ConfusionMatrixDisplay(confusion_matrix = cm_rbf, display_labels = rbf.classes_)\n",
    "\n",
    "#print accuracy and confusion matrix\n",
    "#print(accuracy_lin)\n",
    "#cm_lin_fig.plot()\n",
    "print(accuracy_poly)\n",
    "cm_poly_fig.plot()\n",
    "#print(accuracy_rbf)\n",
    "#cm_rbf_fig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1ac35-5495-4312-89c6-a9aaf7cf1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save confusion matrices\n",
    "cm_lin_fig.figure_.savefig(os.path.join(confusion_path, group_folder, 'lin.png'), dpi = 300)\n",
    "cm_poly_fig.figure_.savefig(os.path.join(confusion_path, group_folder, 'poly.png'), dpi = 300)\n",
    "cm_rbf_fig.figure_.savefig(os.path.join(confusion_path, group_folder, 'rbf.png'), dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e938f-5ead-44e4-8d2c-ea177e634cae",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a501000-7405-4f6d-93ae-e6758a4be04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_classes = list(range(len(y_train.unique())))\n",
    "\n",
    "xg_y_train = y_train.replace(y_train.unique(), xg_classes)\n",
    "xg_y_test = y_test.replace(y_test.unique(), xg_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fd707-e0c1-4a4d-86b6-147d805ff535",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl = xgb.XGBClassifier().fit(X_train, xg_y_train)\n",
    "\n",
    "#get accuracy\n",
    "accuracy_xgb = xg_cl.score(X_test, xg_y_test)\n",
    "print(accuracy_xgb)\n",
    "\n",
    "#plot confusion matrix\n",
    "xgb_pred = xg_cl.predict(X_test)\n",
    "cm_xgb = confusion_matrix(xg_y_test, xgb_pred)\n",
    "cm_xgb_fig = ConfusionMatrixDisplay(cm_xgb)\n",
    "cm_xgb_fig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bd23d-9c81-48ba-b4f5-8eb8f8439d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "cm_xgb_fig.figure_.savefig(os.path.join(confusion_path, group_folder, 'xgb.png'), dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
